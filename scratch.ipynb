{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3453d95-19a7-47fa-9142-4e7cb3e45c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import importlib\n",
    "import teenygpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b099452-18d3-4c88-8f0f-75e66da84f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text.\n",
    "with open(\"data/tiny_shakespeare.txt\", \"rt\", encoding=\"utf-8-sig\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Set up encoder.\n",
    "encoder = teenygpt.CharEncoder(text)\n",
    "\n",
    "# Set up datasets.\n",
    "dataset_train, dataset_val, dataset_test = teenygpt.create_datasets(text, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36d6fa8-15d6-4918-80fe-29383b12ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 ' down,\\nAnd pay y'      'down,\\nAnd pay yo'\n",
      " 1 'e will meet them'       ' will meet them,'\n",
      " 2 'd let it be more'       ' let it be more '\n",
      " 3 'titchery; I must'       'itchery; I must '\n",
      " 4 \"e welcome: what'\"       \" welcome: what's\"\n",
      " 5 't do well, I do '       ' do well, I do n'\n",
      " 6 'e half of my lan'       ' half of my land'\n",
      " 7 'nceit, my gracio'       'ceit, my graciou'\n",
      " 8 'here protest,\\nUp'      'ere protest,\\nUpo'\n",
      " 9 ' supply the room'       'supply the room:'\n",
      "10 'all be satisfied'       'll be satisfied\\n'\n",
      "11 'conditions, whic'       'onditions, which'\n",
      "12 ' legs and not pr'       'legs and not pre'\n",
      "13 'y your voices, w'       ' your voices, wi'\n",
      "14 'an; against whos'       'n; against whose'\n",
      "15 'rson than myself'       'son than myself,'\n",
      "16 ' III:\\nO Ratcliff'      'III:\\nO Ratcliff,'\n",
      "17 'r:\\nI wis it is n'      ':\\nI wis it is no'\n",
      "18 't up.\\n\\nANTIGONUS'     ' up.\\n\\nANTIGONUS:'\n",
      "19 'my spiriting gen'       'y spiriting gent'\n"
     ]
    }
   ],
   "source": [
    "xs, ys = dataset_train.get_batches(teenygpt.Config())\n",
    "\n",
    "for i in range(len(ys)):\n",
    "    x = repr(encoder.decode(xs[i].tolist()))\n",
    "    y = repr(encoder.decode(ys[i].tolist()))\n",
    "    print(f\"{i:2} {x:24} {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "277f30b7-7c3c-470b-a80f-711c96958e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'teenygpt' from '/Volumes/git/src/achang/teenyGPT/teenygpt/__init__.py'>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(teenygpt.config)\n",
    "importlib.reload(teenygpt.model)\n",
    "importlib.reload(teenygpt.model_bkitano)\n",
    "importlib.reload(teenygpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e9a2eec3-92a8-422e-98d6-a07c5c298fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = teenygpt.Config(\n",
    "    vocab_size=67,\n",
    "    batch_size=128,\n",
    "    d_model=128,\n",
    "    d_ffn=128,\n",
    "    attention_heads=8,\n",
    "    attention_layers=4,\n",
    "    dropout_p=0.1,\n",
    ")\n",
    "#losses = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a0b7cf18-709b-4a26-9c8d-da44efae4f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters: 543432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss: 1.09:  71%|█████████████████████████████████████████████████████████████████████████████▍                               | 3553/5000 [09:43<04:23,  5.48it/s][E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "val_loss: 1.09:  71%|█████████████████████████████████████████████████████████████████████████████▍                               | 3554/5000 [09:43<03:57,  6.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m             progress\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, val_losses\n\u001b[0;32m---> 36\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m losses \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_losses, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_losses}\n\u001b[1;32m     38\u001b[0m losses_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({k: pd\u001b[38;5;241m.\u001b[39mSeries(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m losses\u001b[38;5;241m.\u001b[39mitems()})\n",
      "Cell \u001b[0;32mIn[219], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(iterations)\u001b[0m\n\u001b[1;32m     14\u001b[0m xs, ys \u001b[38;5;241m=\u001b[39m dataset_train\u001b[38;5;241m.\u001b[39mget_batches(config)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(logits, ys)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/teenygpt/model.py:262\u001b[0m, in \u001b[0;36mAttentionModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    261\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(inputs)\n\u001b[0;32m--> 262\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x)\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/teenygpt/model.py:159\u001b[0m, in \u001b[0;36mAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# Multi-head attention w/ pre-layer-norm.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     x_attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_multihead_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrms_norm_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Residual block #1.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     x_res_1 \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m x_attn\n",
      "File \u001b[0;32m/Volumes/git/src/achang/teenyGPT/teenygpt/model.py:235\u001b[0m, in \u001b[0;36mAttentionBlock._multihead_attention\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    225\u001b[0m v_proj_heads \u001b[38;5;241m=\u001b[39m v_proj\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    226\u001b[0m     batch_size, window_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mattention_heads, head_dim\n\u001b[1;32m    227\u001b[0m )\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    228\u001b[0m o_heads \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(\n\u001b[1;32m    229\u001b[0m     q_proj_heads,\n\u001b[1;32m    230\u001b[0m     k_proj_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdropout_p,\n\u001b[1;32m    234\u001b[0m )\n\u001b[0;32m--> 235\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43mo_heads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_o(o)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = teenygpt.LlamaModel(config, \"LlamaModel\")\n",
    "model = teenygpt.AttentionModel(config, \"AttentionModel - v4\")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "print(f'model parameters: {model.param_count()}')\n",
    "\n",
    "def train(iterations):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_loss = math.inf\n",
    "    \n",
    "    progress = tqdm(range(iterations))\n",
    "    for i in progress:\n",
    "        xs, ys = dataset_train.get_batches(config)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(xs)\n",
    "        loss = model.loss(logits, ys)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        if i % 10 == 0:\n",
    "            train_loss = model.estimate_loss(dataset_train)\n",
    "            val_loss = model.estimate_loss(dataset_val)\n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            \n",
    "            best_loss = min(best_loss, val_loss)\n",
    "            progress.set_description(f\"val_loss: {best_loss:0.2f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "train_losses, val_losses = train(5000)\n",
    "losses = losses | {f\"train ({model.name})\": train_losses, f\"val ({model.name})\": val_losses}\n",
    "losses_df = pd.DataFrame({k: pd.Series(v) for k, v in losses.items()})\n",
    "losses_df.plot()\n",
    "losses_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "124df995-1d8e-4edc-901e-e7d855ccb382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413511"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teenygpt.AttentionModel(\n",
    "    teenygpt.Config(\n",
    "        vocab_size=67,\n",
    "        batch_size=64,\n",
    "        d_model=128,\n",
    "        attention_heads=8,\n",
    "        attention_layers=3,\n",
    "        dropout_p=0.1,\n",
    "    ),\n",
    "\"dummy\").param_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295568ae-2efb-4ba5-acab-1321edc3d581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a7746ce-ef40-4cfe-afdf-2a55c2c99677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" down,\\nAnd pay yourst,\\nStenter not.\\na we speak:\\nAnge-pole he 'trayal nhegele's comess: I no the foor thest\\nWill for \"\n",
      "\"e will meet them, loes have well atccedried me?\\n\\n\\nGLOUCESTESBY:\\n\\nKING ROK:\\nBy, redet, Lecomengen'd? droof.\\n\\nAUTOESn \"\n",
      "\"d let it be more mince,\\nBoth remeanies, or thy low-k noble'd like\\nAnd 'ses drumngerating our me\\nTraining the sonleea\"\n",
      "\"titchery; I must and Kin,\\nO gaint notreast\\nFor us gooIr am say like? Forbad, you, my unig band reace,\\nI'll my suturn\"\n",
      "\"e welcome: what's lay Sergerowart here'el,\\nFain\\nFerelmard me frisitshfuld?\\n\\nANTONIO:\\nO, good now befe I reselver,\\nIs\"\n",
      "'t do well, I do idnot fe, behopard, I foge I must prerson as excills and prayed my court,\\nAnd\\nnones what pame\\nFectur'\n",
      "'e half of my landes!\\n\\nMAtcENIO:\\nUas I\\nWARINA:\\nThough ponate, as ome draiter confort, Chartion, fur prayed by resome '\n",
      "'nceit, my graciousan, lead me cumble a limess and me\\nAs Cirtizen and pyour thansess,\\nWhen?\\nWhy, would is MursEraUR:\\n'\n",
      "'here protest,\\nUp the we it,\\nI mayserserve it yet lemptiness;\\nBeghostle fiole our lovess powerse! Well,\\nWhy tell youv'\n",
      "\" supply the room as before here in kin GlAseanty;\\nAnd joy,\\nSteell; poulsasera be'er murde orior munce to titlal? how\"\n",
      "\"all be satisfieds\\nTo poolfusely he wrome: is must my stay-me;\\nTo severe you a way:\\nI, he made mere wow,\\nMatcher'd de\"\n",
      "\"conditions, which in here Oxfulier is sit shad.\\n\\nCAONTIO:\\nPesters, thourty ret'er a strufftum the rufff the secze, m\"\n",
      "' legs and not prectod lade henryes.\\n\\nMONTAGAUE:\\nSir, look erenathd\\nHere cann Erge-liegnatin wrispancess us brespikes'\n",
      "'y your voices, will, you bevoly I stande set, somet.\\n\\nThe hims, dreat thusely mightrent pritchfence; or ranoughter d'\n",
      "\"an; against whose mave cark'd:\\nSair, it, Carelorament befelown bid earth teal hirle as greet hWhy am wat Romes, What\"\n",
      "'rson than myself, usal, hed calonver.\\n\\nHARTINAN:\\nBut my king neved; the curdilsmastancess?\\n\\nThe alme:\\nSchall.\\n\\nLABER'\n",
      "\" III:\\nO Ratclifftlement\\nSadet, lue as sweet sake imperserive'd alatto a powelet's be roquestion ourself?\\n\\nANGELO:\\nFe\"\n",
      "'r:\\nI wis it is not.\\n\\nLOCIOMINIUS:\\nIth bat ha? who havome the did me,\\nThere!\\n\\ndear Youl wast are of shalveried?\\n\\nKING'\n",
      "'t up.\\n\\nANTIGONUS:\\nI ame shummed well heave once; your beaur Martcham,\\nAnd is I spellenge\\nTo stick-mess pur by beaut '\n",
      "'my spiriting gentle uncempled heave? a I raige\\nBy pritale; ramerresssion, hattre,\\nFatel to it age\\nFaunsiusal, stares'\n"
     ]
    }
   ],
   "source": [
    "generated = model.generate(xs, count=100)\n",
    "for i in range(generated.shape[b0]):\n",
    "    print(repr(encoder.decode(generated[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4015bb61-9765-4b73-bdda-9c0ed664298b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e90e3-1f2b-45da-be17-91b42bc8582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "    input='data/tiny_shakespeare.txt',\n",
    "    model_prefix='model/sentencepiece/tiny_shakespeare_67',\n",
    "    vocab_size=67,\n",
    "    remove_extra_whitespaces=False,\n",
    "    character_coverage=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b761c0-37a7-4a14-9381-2a965f792473",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = spm.SentencePieceProcessor(\n",
    "    model_file=\"model/sentencepiece/tiny_shakespeare.model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b92345-0a6a-466c-ae6d-8b439c9b6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = processor.encode('this is a test', add_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57898984-c4c5-4d5c-ba82-b3183143a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e66bd5b-b748-4319-8820-59f4c671d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.piece_to_id('<s>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
